{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "load_config() takes 0 positional arguments but 1 was given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 324\u001b[0m\n\u001b[1;32m    321\u001b[0m     args \u001b[38;5;241m=\u001b[39m parser\u001b[38;5;241m.\u001b[39mparse_args()\n\u001b[1;32m    322\u001b[0m     config_path \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mconfig\n\u001b[0;32m--> 324\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 20\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(config_path)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m(config_path: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     17\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m    Main function to load configuration, preprocess data, create charts, and save Excel file.\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[43mload_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     validate_config(config)\n\u001b[1;32m     22\u001b[0m     data \u001b[38;5;241m=\u001b[39m load_data(config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile_path\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mTypeError\u001b[0m: load_config() takes 0 positional arguments but 1 was given"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.formatting.rule import ColorScaleRule\n",
    "from openpyxl.styles import Alignment\n",
    "from openpyxl.utils import get_column_letter\n",
    "import argparse\n",
    "import sys\n",
    "from typing import List, Dict\n",
    "\n",
    "def main(config_path: str):\n",
    "    \"\"\"\n",
    "    Main function to load configuration, preprocess data, create charts, and save Excel file.\n",
    "    \"\"\"\n",
    "    config = load_config(config_path)\n",
    "    validate_config(config)\n",
    "    data = load_data(config['file_path'])\n",
    "    data = preprocess_data(data)\n",
    "    output_folder = os.path.join(config['output_folder'], f\"{config['unidade']}_{config['periodo']}\")\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    create_charts(data, output_folder, config['unidade'], config['periodo'], config)\n",
    "    save_copy_of_source_file_as_excel(data, output_folder, config['unidade'], config['periodo'], config)\n",
    "\n",
    "# Configurar o logger\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def load_config() -> Dict:\n",
    "    \"\"\"\n",
    "    Loads configuration from a YAML file located at a specific path.\n",
    "\n",
    "    Returns:\n",
    "        dict: Configuration data.\n",
    "    \"\"\"\n",
    "    config_path = \"/home/roni-chittoni/ProjectsHub/GAPD/core/laboratorio/config/yaml_files/monitor_colheita.yaml\"\n",
    "    \n",
    "    # Verifica se o arquivo existe antes de tentar carregar\n",
    "    if not os.path.exists(config_path):\n",
    "        logger.error(f\"Configuration file not found at {config_path}\")\n",
    "        raise FileNotFoundError(f\"Configuration file not found at {config_path}\")\n",
    "\n",
    "    try:\n",
    "        with open(config_path, 'r') as file:\n",
    "            config = yaml.safe_load(file)\n",
    "        logger.info(f\"Configuration loaded successfully from {config_path}\")\n",
    "        return config\n",
    "    except yaml.YAMLError as e:\n",
    "        logger.error(f\"Error parsing YAML file: {e}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Unexpected error loading configuration: {e}\")\n",
    "        raise\n",
    "\n",
    "def validate_config(config: Dict):\n",
    "    \"\"\"\n",
    "    Validates the configuration to ensure all required fields are present.\n",
    "\n",
    "    Args:\n",
    "        config (dict): Configuration data.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If any required field is missing.\n",
    "    \"\"\"\n",
    "    required_fields = ['file_path', 'stacked_chart_variables', 'violin_plot_columns', 'output_folder',\n",
    "                       'unidade', 'periodo', 'stacked_chart_titles', 'violin_plot_title', 'violin_plot_x_labels',\n",
    "                       'violin_plot_x_axis_label', 'violin_plot_y_axis_label', 'excel_columns_to_drop', \n",
    "                       'excel_conditional_formatting_columns']\n",
    "    missing_fields = [field for field in required_fields if field not in config]\n",
    "    if missing_fields:\n",
    "        raise ValueError(f\"Missing required configuration fields: {missing_fields}\")\n",
    "    logger.info(\"Configuration validated successfully\")\n",
    "\n",
    "def load_data(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads data from a CSV file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Loaded data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = pd.read_csv(file_path)\n",
    "        logger.info(f\"Data loaded successfully from {file_path}\")\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        logger.error(f\"File not found: {file_path}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading data: {e}\")\n",
    "        raise\n",
    "\n",
    "def preprocess_data(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Preprocesses data by converting dates and reordering columns.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): Data to preprocess.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Preprocessed data.\n",
    "    \"\"\"\n",
    "    data = convert_dates(data)\n",
    "    data = reorder_columns(data)\n",
    "    logger.info(\"Data preprocessed successfully\")\n",
    "    return data\n",
    "\n",
    "def convert_dates(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Converts UTC dates to BRT.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): Data containing the 'Submit Date (UTC)' column.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Data with converted dates.\n",
    "    \"\"\"\n",
    "    data['Submit Date (UTC)'] = pd.to_datetime(data['Submit Date (UTC)']).dt.tz_localize('UTC').dt.tz_convert('America/Sao_Paulo')\n",
    "    data['Submit Date (UTC)'] = data['Submit Date (UTC)'].dt.tz_localize(None)\n",
    "    data.rename(columns={'Submit Date (UTC)': 'Submit Date (BRT)'}, inplace=True)\n",
    "    return data\n",
    "\n",
    "def reorder_columns(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reorders columns to place 'Submit Date (BRT)' first.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): Data to reorder columns.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Data with reordered columns.\n",
    "    \"\"\"\n",
    "    cols = list(data.columns)\n",
    "    cols.insert(0, cols.pop(cols.index('Submit Date (BRT)')))\n",
    "    data = data[cols]\n",
    "    return data\n",
    "\n",
    "def create_stacked_count_chart(data: pd.DataFrame, output_folder: str, unidade: str, periodo: str, column: str, title: str):\n",
    "    \"\"\"\n",
    "    Creates and saves a stacked bar chart.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): Data for the chart.\n",
    "        output_folder (str): Folder to save the chart.\n",
    "        unidade (str): Unit name.\n",
    "        periodo (str): Period.\n",
    "        column (str): Column for the stacked chart.\n",
    "        title (str): Title for the chart.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    counts = data.groupby(['Seu nome', column]).size().unstack(fill_value=0)\n",
    "\n",
    "    # Define the specific colors for notes 1 to 5\n",
    "    color_mapping = {\n",
    "        1: '#ff9999',  # Red\n",
    "        2: '#ffcc99',  # Orange\n",
    "        3: '#ffff99',  # Yellow\n",
    "        4: '#99ff99',  # Green\n",
    "        5: '#99ccff'   # Blue\n",
    "    }\n",
    "    \n",
    "    # Get the unique column values (notes) and map them to colors\n",
    "    unique_columns = counts.columns\n",
    "    colors = [color_mapping[note] for note in unique_columns if note in color_mapping]\n",
    "\n",
    "    # Check if the number of colors matches the number of columns\n",
    "    if len(colors) != len(unique_columns):\n",
    "        raise ValueError(\"Number of defined colors does not match the number of unique categories.\")\n",
    "\n",
    "    ax = counts.plot(kind='bar', stacked=True, color=colors)\n",
    "\n",
    "    for container in ax.containers:\n",
    "        labels = [f'{int(v)}' if v > 0 else '' for v in container.datavalues]\n",
    "        ax.bar_label(container, labels=labels, label_type='center', fontsize=8)\n",
    "\n",
    "    plt.title(f'{title} - {periodo}')\n",
    "    plt.xlabel('Seu nome')\n",
    "    plt.ylabel('Counts')\n",
    "    plt.tight_layout()\n",
    "    ax.grid(True, which='both', linestyle='--', linewidth=0.5, color='lightgrey')\n",
    "    ax.set_axisbelow(True)\n",
    "    output_path = os.path.join(output_folder, f'stacked_bar_{column}.png')\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "    logger.info(f\"Stacked bar chart for {column} saved at {output_path}\")\n",
    "\n",
    "def filter_numeric_columns(data: pd.DataFrame, numeric_columns: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filters numeric columns from the data.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): Data to filter.\n",
    "        numeric_columns (list): List of numeric column names.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Data with only numeric columns.\n",
    "    \"\"\"\n",
    "    return data[numeric_columns]\n",
    "\n",
    "def create_violin_plot(data: pd.DataFrame, unidade: str, periodo: str, config: Dict) -> str:\n",
    "    \"\"\"\n",
    "    Creates a violin plot.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): Data for the plot.\n",
    "        unidade (str): Unit name.\n",
    "        periodo (str): Period.\n",
    "        config (dict): Configuration data.\n",
    "\n",
    "    Returns:\n",
    "        str: Filename of the saved plot.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    ax = sns.violinplot(data=data, orient='h')\n",
    "    ax.set_xticks([1, 2, 3, 4, 5])\n",
    "    ax.set_xticklabels(config['violin_plot_x_labels'])\n",
    "    plt.title(f\"{config['violin_plot_title']} - {unidade} - {periodo}\")\n",
    "    plt.xlabel(config['violin_plot_x_axis_label'])\n",
    "    plt.ylabel(config['violin_plot_y_axis_label'])\n",
    "    plt.tight_layout()\n",
    "    ax.grid(True, which='both', linestyle='--', linewidth=0.5, color='lightgrey')\n",
    "    ax.set_axisbelow(True)\n",
    "    filename = f'violin_plot_{unidade}_{periodo}.png'\n",
    "    return filename\n",
    "\n",
    "def save_plot(filename: str, output_folder: str):\n",
    "    \"\"\"\n",
    "    Saves the current plot to a file.\n",
    "\n",
    "    Args:\n",
    "        filename (str): Filename to save the plot.\n",
    "        output_folder (str): Folder to save the plot.\n",
    "    \"\"\"\n",
    "    output_path = os.path.join(output_folder, filename)\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "    logger.info(f\"Violin plot saved at {output_path}\")\n",
    "\n",
    "def apply_conditional_formatting(ws, columns: List[str]):\n",
    "    \"\"\"\n",
    "    Applies conditional formatting to specified columns in an Excel worksheet.\n",
    "\n",
    "    Args:\n",
    "        ws (openpyxl.worksheet.worksheet.Worksheet): Worksheet to format.\n",
    "        columns (list): List of column letters to apply formatting.\n",
    "    \"\"\"\n",
    "    for col in columns:\n",
    "        c_range = f\"{col}2:{col}{ws.max_row}\"\n",
    "        rule = ColorScaleRule(start_type='num', start_value=1, start_color='FFB3BA',\n",
    "                              mid_type='num', mid_value=3, mid_color='FFDFBA',\n",
    "                              end_type='num', end_value=5, end_color='BAE1FF')\n",
    "        ws.conditional_formatting.add(c_range, rule)\n",
    "        for row in ws[c_range]:\n",
    "            for cell in row:\n",
    "                cell.alignment = Alignment(horizontal='center')\n",
    "\n",
    "def save_copy_of_source_file_as_excel(data: pd.DataFrame, output_folder: str, unidade: str, periodo: str, config: Dict):\n",
    "    \"\"\"\n",
    "    Saves a copy of the source data as an Excel file with conditional formatting.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): Data to save.\n",
    "        output_folder (str): Folder to save the file.\n",
    "        unidade (str): Unit name.\n",
    "        periodo (str): Period.\n",
    "        config (dict): Configuration data.\n",
    "    \"\"\"\n",
    "    columns_to_drop = config['excel_columns_to_drop']\n",
    "    data = data.drop(columns=columns_to_drop, errors='ignore')\n",
    "    base_name = f'{unidade}_{periodo}'\n",
    "    new_file_path = os.path.join(output_folder, f'{base_name}.xlsx')\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    with pd.ExcelWriter(new_file_path, engine='openpyxl') as writer:\n",
    "        data.to_excel(writer, index=False, sheet_name='Sheet1')\n",
    "        workbook = writer.book\n",
    "        worksheet = writer.sheets['Sheet1']\n",
    "        worksheet.auto_filter.ref = worksheet.dimensions\n",
    "    wb = load_workbook(new_file_path)\n",
    "    ws = wb.active\n",
    "    columns = config['excel_conditional_formatting_columns']\n",
    "    column_letters = [get_column_letter(data.columns.get_loc(col) + 1) for col in columns]\n",
    "    apply_conditional_formatting(ws, column_letters)\n",
    "    wb.save(new_file_path)\n",
    "    print(f'Cópia do arquivo de origem salva em: {new_file_path}')\n",
    "\n",
    "def create_charts(data: pd.DataFrame, output_folder: str, unidade: str, periodo: str, config: Dict):\n",
    "    \"\"\"\n",
    "    Creates and saves charts based on the configuration.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): Data for the charts.\n",
    "        output_folder (str): Folder to save the charts.\n",
    "        unidade (str): Unit name.\n",
    "        periodo (str): Period.\n",
    "        config (dict): Configuration dictionary.\n",
    "    \"\"\"\n",
    "    stacked_chart_columns = config['stacked_chart_variables']\n",
    "    for column in stacked_chart_columns:\n",
    "        title = config['stacked_chart_titles'][column]\n",
    "        create_stacked_count_chart(data, output_folder, unidade, periodo, column, title)\n",
    "    numeric_columns = config['violin_plot_columns']\n",
    "    data_numeric = filter_numeric_columns(data, numeric_columns)\n",
    "    filename = create_violin_plot(data_numeric, unidade, periodo, config)\n",
    "    save_plot(filename, output_folder)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if 'ipykernel' in sys.argv[0]:\n",
    "        # Executado no Jupyter Notebook\n",
    "        config_path = 'monitor_colheita.yaml'\n",
    "    else:\n",
    "        # Executado no terminal\n",
    "        parser = argparse.ArgumentParser(description='Survey Response Analysis')\n",
    "        parser.add_argument('--config', type=str, default='monitor_colheita.yaml', help='Path to the configuration file')\n",
    "        args = parser.parse_args()\n",
    "        config_path = args.config\n",
    "    \n",
    "    main(config_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "monitor_colheita",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
